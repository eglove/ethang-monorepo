<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>How an Industry Traded Discipline for Dopamine</title>
    <meta
      name="description"
      content="An in-depth perspective on the concerning trends of AI adoption in web development, exploring issues of trust, security, and the illusion of productivity."
    />

    <meta
      property="og:title"
      content="How an Industry Traded Discipline for Dopamine"
    />
    <meta
      property="og:description"
      content="An in-depth perspective on the concerning trends of AI adoption in web development, exploring issues of trust, security, and the illusion of productivity."
    />
    <meta property="og:type" content="article" />
    <meta property="og:url" content="/blog/discipline-for-dopamine" />
    <meta property="og:image" content="/images/bright-ball-tech.png" />
    <meta
      property="og:image:alt"
      content="A futuristic image showing a network of data with a central AI core in a state of decay."
    />

    <link href="https://fonts.googleapis.com" rel="preconnect" />
    <link crossorigin href="https://fonts.gstatic.com" rel="preconnect" />
    <link
      href="https://fonts.googleapis.com/css2?family=Funnel+Sans:ital,wght@0,300..800;1,300..800&display=swap"
      rel="stylesheet"
    />

    <style>
      body {
        font-family: "Funnel Sans", sans-serif;
        background-color: #111827;
        color: #e5e7eb;
        line-height: 1.75;
      }

      .container {
        max-width: 64rem;
        margin-left: auto;
        margin-right: auto;
        padding: 2rem 1rem;
      }

      .blog-link {
        display: inline-flex;
        align-items: center;
        color: #60a5fa;
        transition: color 300ms ease-in-out;
        margin-bottom: 2rem;
      }

      a,
      a:visited {
        color: #60a5fa;
      }

      .blog-link:hover {
        color: #93c5fd;
      }

      .blog-link svg {
        width: 1rem;
        height: 1rem;
        margin-right: 0.5rem;
      }

      .article-content {
        background-color: #1f2937;
        padding: 2rem;
        border-radius: 0.75rem;
        box-shadow:
          0 20px 25px -5px rgba(0, 0, 0, 0.1),
          0 10px 10px -5px rgba(0, 0, 0, 0.04);
      }

      .article-title {
        font-size: 2.25rem;
        font-weight: 800;
        color: #60a5fa;
        margin-bottom: 1.5rem;
        line-height: 1.25;
      }

      .article-subtitle {
        font-size: 1.25rem;
        margin-bottom: 2rem;
        color: #9ca3af;
      }

      .prose p {
        margin-bottom: 1rem;
      }

      ::-webkit-scrollbar {
        width: 8px;
      }
      ::-webkit-scrollbar-track {
        background: #1f2937;
      }
      ::-webkit-scrollbar-thumb {
        background: #4b5563;
        border-radius: 10px;
      }
      ::-webkit-scrollbar-thumb:hover {
        background: #6b7280;
      }

      @media (min-width: 768px) {
        .article-content {
          padding: 3rem;
        }
        .article-title {
          font-size: 3rem;
        }
      }
    </style>
  </head>
  <body>
    <div class="container">
      <a href="/blog" class="blog-link">
        <svg
          class="w-4 h-4 mr-2"
          stroke="currentColor"
          viewBox="0 0 24 24"
          xmlns="http://www.w3.org/2000/svg"
        >
          <path
            stroke-linecap="round"
            stroke-linejoin="round"
            stroke-width="2"
            d="M10 19l-7-7m0 0l7-7m-7 7h18"
          ></path>
        </svg>
        Back to blog
      </a>

      <article class="article-content">
        <h1 class="article-title">
          How an Industry Traded Discipline for Dopamine
        </h1>

        <p class="article-subtitle">
          A perspective on the current state of web development and the
          concerning trends of AI adoption.
        </p>

        <div class="prose">
          <p>
            I have 588 subscriptions in my RSS reader. This includes dozens of
            mailing lists with their own curation. My newsletter on LinkedIn is
            mostly derivative of these feeds.
          </p>
          <p>
            Over the past couple of weeks I&rsquo;ve seen a drastic slowdown in
            news around web development. Over the past couple of months it was
            almost exclusively about AI.
          </p>
          <p>
            Within that AI news, I saw three major recurring themes. Trust in AI
            keeps plummeting, security issues caused by AI keep rising. The
            usage of AI keeps skyrocketing.
          </p>
          <p>
            This is a very concerning trend. Contractors know it all too well.
            The usage of this technology is an addiction, not a solution.
            It&rsquo;s causing more harm than good. Anyone with dedicated
            expertise in full-time refactoring and rewrites knows that companies
            won&rsquo;t realize how bad things are for a few years. They have
            moved to a diet of fast food thinking it&rsquo;s healthy.
            They&rsquo;re gaining weight but not used to weighing themselves and
            not noticing the gains. At the first major data leak, they will hand
            wave it off as a regular problem to deal with. It won&rsquo;t be
            until at least a heart attack that they take the problem seriously.
            And by then, they&rsquo;ll be doubled down on the bad habits looking
            for a magic pill.
          </p>
          <p>
            I want to be clear that I think this current AI problem is unique.
            This isn&rsquo;t the sort of situation you can unironically say,
            &ldquo;First they think you&rsquo;re crazy, then they fight you, and
            then all of a sudden you change the world.&rdquo;
          </p>
          <p>
            People have been calling React the death of the web for as long as
            React has been around. And there are a few good arguments to be made
            against it. Primarily around performance, hooks, and the virtual
            DOM.
          </p>
          <p>
            But when React became popular, developers were excited to share real
            projects they built. Ecommerce stores, trading platforms,
            productivity dashboards. The SPA architecture created an explosion
            in real web innovation.
          </p>
          <p>
            With AI and vibe coding this just isn&rsquo;t happening. People are
            talking about how much more productive they feel, but they&rsquo;re
            not sharing open source work. Just bragging about the number of
            lines of code they&rsquo;ve &ldquo;written.&rdquo; Weeks later, they
            give up complaining about the number of bugs and inability to scale.
          </p>
          <p>
            I feel like when CEO&rsquo;s looking to sell AI started telling
            everyone it was going to take their jobs, people started trying to
            make it take their jobs. Insisting that it was doing a perfect job.
            The fear of being replaced created an odd reaction where people
            insisted it was true despite evidence to the contrary.
          </p>
          <p>
            I also think there are a few other cognitive heuristics at play
            here. A sunk cost fallacy is one of many. Developers paid for tools
            like Cursor. For many of them it was the first time they&rsquo;d
            invested in an editor. They then spent thousands on API tokens.
            Watching AI spit out &ldquo;thoughts&rdquo; in realtime became a
            similar addiction to watching a download progress bar. Or the
            progress bars seen in mobile idle games. Or the cast, health, and
            experience bars seen in RPG and MMO games like World of Warcraft.
            Their movement indicates progress, which releases dopamine.
          </p>
          <p>
            And so you see my concern. And there are two additional notes I want
            to add to help establish my perspective. One, I don&rsquo;t get my
            news from social media algorithms. Two, I seem to have a natural
            contrarian mechanism.
          </p>
          <p>
            That mechanism has saved me from the allure of a cult twice before.
            One cult being wrapped in a political movement; the other is a group
            called Source Allies. This mechanism also prevents me from some
            healthy things. I don&rsquo;t &ldquo;get&rdquo; live events, or how
            people get caught up in collective energy. And religion is
            challenging for me to understand without historical evidence such as
            the gospels.
          </p>
          <p>
            I want to establish the fact that I do not get my news from social
            media algorithms, and that I am unaffected by
            <a
              href="https://en.wikipedia.org/wiki/Deindividuation"
              target="_blank"
              rel="noopener noreferrer"
              >deindividuation</a
            >. The reason is to establish some level of credibility to my unique
            perspective on the current state of the industry. This is the
            perspective I use to look at hundreds of RSS subscriptions talking
            about a lack of trust in AI and major security concerns. The
            positivity and practical value simply aren&rsquo;t there. All the
            perceived practical value and positivity is in crowd psychology.
          </p>
          <p>
            When I say we are headed for disaster, I&rsquo;m thinking along the
            same lines of plastic. We are creating an economic dependence on
            something that is destroying the ecosystem and leaving ourselves
            with mountains of tech debt equal to that of the
            <a
              href="https://en.wikipedia.org/wiki/Great_Pacific_Garbage_Patch"
              target="_blank"
              rel="noopener noreferrer"
              >Great Pacific Garbage Patch</a
            >.
          </p>
          <p>
            When AI first started to become popular, many developers started to
            say this is a good time to start expanding your responsibility.
            Become more concerned with testing, architecture, requirement
            gathering, software design, refactoring skills. But the truth is, if
            they weren&rsquo;t concerned with these things before, they
            won&rsquo;t be now. And that&rsquo;s exactly what we see. Vibe
            coders are too busy bragging about how they told AI to write 10,000
            lines of code and taking credit for it to care about the things they
            were supposed to be freeing up their time for.
          </p>
          <p>
            On every practical level, AI code generation seems to be an utter
            failure.
          </p>
          <p>
            Before I get to the core point, I want to add one more anecdote. If
            you&rsquo;re into modding video games, you may be aware of the many
            tools and systems to help install large 1,000–2,000 mod
            &ldquo;collections&rdquo; or &ldquo;lists.&rdquo; Tools like
            Wabbajack, Vortex (by Nexus Mods), and other similar tools are meant
            to organize and share these lists.
          </p>
          <p>
            These tools primarily share a &ldquo;load order&rdquo; and handle
            the download and installation of these mods. But that is only a
            fraction of the work involved. Building a load order to handle
            conflicts and compatibility patches is not easy at the scale of
            1,000+ mods. Wabbajack and Vortex act as the &ldquo;package
            manager&rdquo; but from there mods can typically only overwrite game
            files or at best hook into the game event system.
          </p>
          <p>
            With thousands of mods, the game is basically guaranteed to
            experience regular crashes, if it even launches at all. With the
            best collection, if some armor clips through a blade of grass, the
            game can crash to desktop. This will happen with any game and any
            combination of mods. Elder Scrolls, Fallout, Witcher, Cyberpunk,
            Minecraft, take your pick.
          </p>
          <p>
            This is a famous, and basically unsolvable problem within the
            modding community. These lists may work for 10 hours of gameplay
            before you start to see the game crash every hour. Modders often
            blame the underlying game engine like Bethesda&rsquo;s Creation
            Engine. But when you see this same issue across publishers, we see
            that&rsquo;s not the problem.
          </p>
          <p>
            The problem is a
            <a
              href="https://en.wikipedia.org/wiki/Combinatorial_explosion"
              target="_blank"
              rel="noopener noreferrer"
              >combinatorial explosion</a
            >. Over time these mods create a confused internal state and
            &ldquo;corrupt save files.&rdquo; Thousands of individually
            developed mods meant to do one simple file overwrite or hook into
            events. Each on their own is causing no particular problem. Even
            with compatibility patches, you&rsquo;re still dealing with a
            complex network of unaccounted-for interactions.
          </p>
          <div style="max-width: 100%">
            <img
              src="/images/mod-complexity.png"
              style="
                display: block;
                width: 100%;
                height: auto;
                object-fit: contain;
                max-width: 100%;
              "
              alt="Mod complexity diagram"
              width="1367"
              height="987"
            />
          </div>
          <p>
            This is what AI is doing with code. At a medium to large scale,
            it&rsquo;s impossible to know the true effects of individual code
            changes. This is why every feature needs comprehensive E2E,
            integration, and unit tests. So that changes are always tested
            against previous requirements. This is why we plan and diagram
            architectures focusing on one &ldquo;concern&rdquo; at a time. Such
            as security, maintainability, performance, scale, API interfaces,
            etc. It&rsquo;s why we use standard API contracts like HAL or
            GraphQL. It&rsquo;s why Margaret Hamilton coined the term
            &ldquo;software engineer.&rdquo; It&rsquo;s why your development job
            wasn&rsquo;t taken by SquareSpace, WordPress, Sitecore, Visual
            Basic, ServiceNow, or any number of no-code attempts.
          </p>
          <p>
            With all these systems that generate code, all of them fall apart
            under the weight of scale and complexity.
          </p>
          <p>
            Even an online image converter can be done on WordPress. Vibe coding
            a React version is no great revolution! It&rsquo;s just another
            low-code tool that can&rsquo;t scale.
          </p>
          <p>
            But what AI has done, by removing the interface and deterministic
            rules of low/no-code tools, is given people the illusion that
            imprecise spoken language could ever equate to the precise language
            of programming and mathematics. And that no-code generations could
            ever possibly account for an infinite number of concerns.
          </p>
          <p>
            A few paragraphs ago, when I said, &ldquo;this is why we
            test,&rdquo; you may have been objecting, &ldquo;AI can generate
            tests.&rdquo; Or, &ldquo;AI can generate diagrams.&rdquo; &ldquo;Ai
            can write code and run tests.&rdquo; If you are saying this,
            I&rsquo;m afraid you&rsquo;ve missed the point entirely.
          </p>
          <p>
            Yes, AI can generate text. And all of these things are just text.
            But if you say this, then you don&rsquo;t understand just how human
            software is!
          </p>
          <p>
            When a civil engineer designs a bridge, surveys the site, talks with
            city representatives, analyzes traffic patterns, writes the
            blueprint, considers weight limits and traffic throughput, safety
            regulations and budget. Which steps do you think it&rsquo;s OK for
            an AI to make a non-deterministic guess? At which point is it OK to
            gamble with people&rsquo;s lives?
          </p>
          <p>
            &ldquo;The engineer uses statistical probability in his work,&rdquo;
            you say. But you know this is different. &ldquo;The engineer could
            do these things faster and review the AI&rsquo;s work after,&rdquo;
            you say.
          </p>
          <p>
            But it is the work and the process that makes their work correct and
            safe! Don&rsquo;t you understand the difference? The work
            isn&rsquo;t just some arbitrary thing in the way of a bridge
            appearing. If the engineer is only reviewing the work of an AI, the
            discipline is lost, the knowledge begins to disappear, the engineer
            becomes both too lazy and too unqualified to even do a review.
            Suddenly we can neither trust AI nor the engineer!
          </p>
          <p>
            And so at what point in the process can we responsibly tell AI to do
            the work in software engineering? I would say in terms of a formal
            process, it should not be allowed in any way.
          </p>
          <div style="max-width: 100%">
            <img
              src="/images/wait-wait-wait.gif"
              style="
                display: block;
                width: 100%;
                height: auto;
                object-fit: contain;
                max-width: 100%;
              "
              alt="wait wait wait meme"
              width="498"
              height="278"
            />
          </div>
          <p>I hear you.</p>
          <p>
            This doesn&rsquo;t prevent you from using it as an advanced Google
            search. The generations of an AI are no more credible than a Stack
            Overflow answer. But neither is actually credible. There MUST be a
            qualified engineer not just reviewing what it returns, but doing the
            work. I&rsquo;m saying AI, like your choice in editor, should not be
            formally taught or assumed to be a part of the process.
          </p>
          <p>
            If you cannot prove the ability, in the day-to-day, to do the job
            responsibly without acting as an AI reviewer, then you are not
            qualified to do the job. It means you cannot be trusted with user
            data or safety in a professional capacity.
          </p>
          <p>
            I think software engineers should hold individual licenses to have a
            legal right to do the job.
          </p>
          <p>
            Professional drivers hold CDL&rsquo;s and are required by federal
            law to have clean driving records. They hold &ldquo;medical
            cards&rdquo; to prove they are physically fit for the endurance
            required to be on the road for long periods of time. Anything even
            related to construction typically requires various levels of regular
            OSHA training. And certification for specific equipment. Plumbers
            and electricians go through apprenticeship programs. Welders require
            not just formal education but regular certification. Nurses must
            pass and maintain a NCLEX-RN license at a minimum. Accountants get a
            CPA. Those in traditional IT get CompTIA or Cisco certified.
          </p>
          <p>
            If software engineers aren&rsquo;t doing this, then we are neither
            engineers nor even skilled labor. In the US, that means an average
            annual salary of $39,000.
          </p>
          <p>
            The age of AI and decline of discipline and responsibility in an
            already undisciplined and irresponsible industry has got me thinking
            a lot about this.
          </p>
          <p>
            &ldquo;I have an AWS certification,&rdquo; you say. OK. That is a
            vendor-specific knowledge and extremely opinionated. Its view on
            default architecture being Lamda functions, and Dynamo is too
            expensive and impractical for most cases.
          </p>
          <p>
            No, I think we need to look toward things like IEEE, which has been
            pushing for these things since the 1990&rsquo;s. A standard
            certification that covers knowledge of architecture, operations,
            security, requirements, design, construction, and testing.
          </p>
          <p>
            Most developers only know construction. If that&rsquo;s the case, I
            do not believe they are qualified to be software engineers. Leetcode
            is not impressive. But because we have grown to see software
            engineering as only construction, we are easily fooled by an AI text
            prediction.
          </p>
          <p>
            From a personal perspective, I have to say this applies to me. I
            have always been interested in learning more about engineering. But
            in nearly every professional environment I&rsquo;ve been in,
            it&rsquo;s actively discouraged. There is a resistance and even
            repulsion to even a half-step in that direction. &ldquo;We should
            unit test.&rdquo; &ldquo;NO! Unit tests are useless, we ship
            here!&rdquo; Companies want to apply agile practices to software
            construction, which ironically removes the need for agile practices,
            or any level of real communication to begin with. If you&rsquo;re
            just slapping code together, why do you need a formal process or
            meetings at all? We see this very real opinion and thought process
            all the time. People don’t understand of processes because they’re
            not engineering. Developers only want to do the construction part,
            and they haven&rsquo;t even done a 10-hour OSHA safety training
            course.
          </p>
          <p>No wonder people think AI can replace programming.</p>
          <p>
            So I have been reading SWEBOK and intend on pursuing IEEE
            certification. Knowing that companies don&rsquo;t look for this and
            won&rsquo;t even know what it is. In fact, it would probably harm my
            potential to get hired if I&rsquo;m viewed as someone who believes
            in producing quality work. But saying I&rsquo;m a veteran also harms
            my job prospects in tech, so what do I have to lose? I am on this
            path because I believe it&rsquo;s the right thing to do.
          </p>
          <p>
            As for where this industry is headed. I feel like it&rsquo;s
            spiraling out of control fast. There will be a name for the results
            of this in the history books. &ldquo;The Great AI Crash.&rdquo; And
            a Wikipedia article with estimated PII leaked, economic crashes, and
            lives lost. And I&rsquo;m not so sure we&rsquo;ll really know what
            to do after.
          </p>
        </div>
      </article>
    </div>
  </body>
</html>
