---
import aiParadoxImage from "../../images/ai-paradox.png";
import WordCount from "../../components/BlogWidgets.astro";
import BlogLayout from "../../layouts/BlogLayout.astro";
---

<BlogLayout title="The AI Paradox">
  <h1>
    The AI Paradox: Why Some Developers Are Underwhelmed and Others See a
    Revolution
  </h1>
  <WordCount
    image={{
      src: aiParadoxImage,
      alt: 'An abstract image illustrating the "AI Paradox." On the left, a developer appears overwhelmed, with hands on their head amidst complex, swirling code and abstract AI elements. On the right, another developer looks confident and a bit triumphant, surrounded by organized code and circuit-like patterns, representing the revolutionary potential of AI. The background is a mix of digital patterns and glowing lines, symbolizing the digital world and the evolving tech landscape.',
    }}
  />

  <p>
    For months, the talk about <strong
      >AI and Large Language Models (LLMs)</strong
    > has been constant. Social media is full of claims about their revolutionary
    potential, promises of faster development, and even warnings about engineers
    becoming obsolete. Yet, many experienced developers, myself included, often find
    all this intense hype surprisingly underwhelming. When asked for real-world examples,
    the stories often involve small side projects or minor bug fixes – impressive,
    perhaps, but hardly the massive shift being suggested.
  </p>

  <p>
    This initial disconnect can be frustrating. It's easy to wonder if it's just
    a marketing push, a widespread delusion, or even a tech bubble, as many
    analysts suggest. The concerns are valid: AI companies are seeing sky-high
    valuations with unclear paths to profit, relying on buzzwords more than
    proven products, and burning cash quickly. This environment naturally
    fosters skepticism, especially when practical applications don't quite live
    up to the grand claims.
  </p>

  <p>
    So, why such a stark divide? Why do some developers see AI as a miracle,
    while others just shrug? After recent discussions and self-reflection, I
    believe a significant part of this disconnect comes down to <strong
      >perspective</strong
    >, heavily influenced by a developer's career experiences. It's not about
    who's smarter; it's about how a developer's role, even at junior and
    mid-levels, can vary dramatically across different experiences and
    organizations.
  </p>

  <h2 id="magicEye">The "Magic Eye" of Development: Differing Realities</h2>

  <p>
    Think about those "magic eye" pictures – a jumble of patterns that reveal a
    hidden image when viewed correctly. The current perception of AI in software
    development feels remarkably similar. Two developers can use the same AI
    tool for the same task and come away with entirely different conclusions
    about its value.
  </p>

  <p>
    For many developers, especially those whose careers involved primarily
    implementing well-defined features within existing structures, <strong
      >AI is genuinely transformative</strong
    >. Their early experiences often meant taking a task, writing boilerplate
    code, or fixing clear-cut bugs. For these roles, where the focus was on
    specific, often routine, "hands-on keyboard" work (the kind often associated
    with traditional junior or mid-level positions), AI’s ability to:
  </p>

  <ul>
    <li>Generate boilerplate code</li>
    <li>Write unit tests for simple functions</li>
    <li>Scaffold components or small applications</li>
    <li>Assist with basic code review and refactoring</li>
    <li>Quickly find API or library information</li>
  </ul>

  <p>
    can truly feel revolutionary. Imagine how much repetitive code can now be
    generated almost instantly, or how much quicker basic configurations can be
    set up. This is where stories of building "an app in 12 hours that used to
    take 3 days" come from. From this viewpoint, it genuinely is a massive leap
    in productivity. Here, AI automates the "grunt work" that used to consume a
    lot of their time, making it feel like a true game-changer.
  </p>

  <h2 id="architectsGaze">The Architect's Gaze: A Different Landscape</h2>

  <p>
    However, some of us, perhaps by fortunate circumstance or a natural
    inclination towards ownership and high-level problem-solving, have had a
    different career path. My own career, for instance, has consistently placed
    me in roles where my main function wasn't just to "code tickets," even as a
    junior engineer. This has meant constantly operating at a strategic and
    architectural level that current AI capabilities simply cannot replicate.
  </p>

  <p>
    In the real world, I’ve repeatedly seen fundamental software development
    problems persist in teams, even among developers with decades more
    experience than I have. I’ve encountered applications that crash weekly,
    widespread errors that are hard to trace, or a complete inability to manage
    data invalidation. Teams often struggle with chaotic state management, using
    multiple custom wrappers around libraries like Zustand without really
    understanding how to control re-renders. I've even seen development teams
    struggle for months to deploy an application, mistakenly thinking a
    framework like Next.js could be served as static files on IIS.
    Unfortunately, these situations are common and often highlight a critical
    gap: a focus on custom solutions without a deep understanding of the
    underlying ecosystem, established libraries, or fundamental deployment
    methods. It seems some experienced professionals, perhaps used to careers
    emphasizing routine code generation, may not have been taught to take these
    critical foundational tasks seriously. Instead, there's a belief that such
    complex issues are secondary, or that "real" work is limited to "DevOps" or
    "cloud" specializations. Crucially, I've often been brought in to fix these
    very issues, even when the development leads and architects on those teams
    were ostensibly senior to me.
  </p>

  <p>
    These aren't "boilerplate" problems. These are deep dives into systemic
    issues, architectural flaws, performance bottlenecks, and the kind of
    creative, holistic thinking that orchestrates a complete, functional product
    from an initial idea. When your daily work involves designing scalable
    systems, debugging elusive cross-system issues, or inventing entirely new
    features, the "magic" of AI generating a simple function or finding a basic
    bug feels... less magical. It seems like an advanced autocomplete, a
    sophisticated search engine, or a souped-up linter – tools that are helpful,
    but not revolutionary to someone who has spent years building internal "AI
    systems" in their own mind to avoid such routine work.
  </p>

  <p>
    Indeed, when a significant part of your career has involved consciously
    eliminating boilerplate, automating CI/CD pipelines, optimizing complex
    frontends for responsiveness and performance, and considering the entire
    stack from concept to deployment, the perceived "wow" factor of LLMs shifts
    dramatically. The things AI currently excels at are often what these
    experienced engineers have already built systems or mental models to
    minimize or automate. For example, my early and junior-level jobs included
    tasks like leading migrations to new frameworks (like Vue or Next.js) for
    teams unfamiliar with them. This involved strategic planning, architectural
    design, team training, and foresight into long-term maintainability. In
    other roles, I built entire team collaboration apps from scratch, including
    real-time video conferencing, chat, and phone calls, which demanded complex
    real-time system design and full-stack optimization. I also rearchitected
    slow REST APIs to new GraphQL APIs due to performance bottlenecks and
    introduced automated testing (unit, E2E, accessibility) to legacy codebases.
  </p>

  <p>
    These experiences, where the core task was often to fix what others had
    struggled to build or maintain due to a lack of deeper architectural
    understanding, highlight a clear distinction. I've routinely been tasked
    with conceptualizing, building from scratch, and even diagnosing and
    re-engineering entire systems – from database design to frontend
    optimization, through CI/CD and deployments. This perspective has
    fundamentally shaped my view: what AI is "fixing" for some are often
    problems stemming from a less comprehensive understanding of the development
    ecosystem, problems that experienced architects and full-stack developers
    proactively avoid or resolve at a much higher level. For those of us who
    have tackled this breadth of responsibility from the outset, no part of the
    development stack feels "beneath" us; everything must be taken seriously.
  </p>

  <h2 id="realWorld">
    Real-World Architectural Challenges vs. AI's Current Strengths
  </h2>

  <p>
    Let’s look at a concrete example from a real-world scenario: re-architecting
    a real-time dashboard for a crypto trading platform. It started as a mess:
    frequent crashes, rampant side effect errors, mysterious data invalidation,
    and uncontrolled re-renders causing noticeable lag. The existing team often
    focused on custom, clunky solutions for data and state.
  </p>

  <p>
    My approach wasn't to write more custom code for every small feature.
    Instead, it leveraged architectural principles and existing ecosystem
    strengths. The first, and most obvious, step was to adopt a robust async
    state management library like TanStack/React Query. Or, I should say this
    was obvious to me, but this team had legitimately never heard of React Query
    and were not aware of the problems it solved. They had the problems to
    complain about, but were unaware of the solutions, so spent months cobbling
    together custom fixes, pushing through, gathering tech debt. Something that
    could have been avoided altogether with a little ecosystem awareness.
  </p>

  <p>
    So just plugging in RQ immediately eliminated hundreds of redundant network
    requests through simple deduplication and ensured efficient data updates and
    invalidation. This is a standard, yet incredibly powerful, React
    optimization that set the foundation.
  </p>

  <p>
    The truly unique part involved optimizing real-time calculations,
    specifically for metrics like Profit/Loss and Greeks on a portfolio. These
    values could update and recalculate dozens of times per second, multiplied
    by the number of positions, potentially leading to hundreds of re-renders
    per second across the UI. To solve this, I managed to isolate re-renders
    down to individual table cells, and by extension, individual mathematical
    formulas (treated as pure functions), rather than re-rendering entire tables
    on price updates. By passing symbol IDs to table cells, using that to look
    up the price in React Query's cache, and only recalculating on a price
    change for that specific symbol, the re-render would only occur if the
    calculation result was different. This approach, largely inspired by
    concepts that challenge React's one-way data flow model for specific
    optimization cases, focused solely on pure functions external to React's
    core render engine, avoiding reliance on memoization.
  </p>

  <p>
    The final piece was maintaining dynamic table sorting. Since table rows
    weren't directly coming from a rapidly updating array, but rather pulling
    data from React Query's cache by symbol ID (which never changed), sorting
    posed a unique challenge. The solution involved recalculating values like
    P&L on the fly from the optimized cache when a user clicked sort, and simply
    reordering the symbol IDs. While this might sound like a performance hit, it
    worked fantastically because the data was already optimized and readily
    available in cache, ensuring re-renders remained contained at a minimal cell
    level.
  </p>

  <p>
    When these architectural and optimization changes were paired with using
    IndexedDB as a persisted read/write-through cache for React Query, we saw
    crucial Core Web Vital field data numbers, such as Interaction to Next Paint
    (INP), at 0ms or near 0ms.
  </p>

  <p>
    This entire process – diagnosing systemic issues, choosing the right tools,
    understanding their deep workings, designing a novel reactive architecture,
    and innovating solutions for complex real-time data flow and UI performance
    – is far beyond what current LLMs can do autonomously. An AI can generate
    code for a table cell or a basic state management setup, but it cannot
    conceive, diagnose, architect, or debug a complex system like this from
    scratch. It cannot look at "hundreds of re-renders per second" and design a
    solution that fundamentally alters how data is processed and presented
    across an entire application.
  </p>

  <h2 id="realImpact">
    The Real Impact and the Evolving Role: Becoming AI-Augmented
  </h2>

  <p>
    This doesn't mean LLMs are useless. Far from it. They are incredibly
    powerful tools. However, their "revolutionary" impact is felt most strongly
    where previous manual effort was highest and most repetitive. It's crucial
    to balance expectations with current realities. The common idea that AI will
    force developers to take on "more responsibility" and "higher-level
    thinking" is mainly directed at those whose careers have historically
    focused on routine tasks. For these individuals, AI can indeed enhance their
    work and act as a force multiplier, automating parts of the coding process.
  </p>

  <p>
    Yet, for many experienced developers, the usefulness of LLMs for specific
    coding tasks remains debatable, and often inefficient. I've personally seen
    LLMs struggle with tasks like converting JavaScript to TypeScript; a file
    with 100 errors might see 50 removed, but 30 new ones introduced, making the
    code 60 times more complex. All this while it takes minutes for an AI to
    produce what a proficient developer can fix in seconds with familiar IDE
    tools. The token cost for such an operation becomes a clear waste of
    resources. Similarly, for generating most components or hooks, if you
    already have the knowledge and muscle memory, writing the code directly is
    often much faster and more cost-effective than prompting and refining AI
    output. This suggests that for proficient developers, many seemingly
    "automatable" coding tasks are still quicker and cheaper to do manually.
  </p>

  <p>
    <strong>This leads to a compelling alternative perspective:</strong> AI's true
    value for experienced developers might not be in generating code, but in <strong
      >reintroducing confidence in one's own time and ability to master the
      entire stack.</strong
    > Instead of relying on AI to generate potentially faulty code for contractors
    to fix, developers can leverage AI as a sophisticated assistant to:
  </p>

  <ul>
    <li>
      <strong>Learn new patterns and concepts:</strong> Use AI to quickly explore
      unfamiliar libraries, design patterns, or architectural approaches, getting
      a head start on understanding complex topics.
    </li>
    <li>
      <strong>Methodically test and debug:</strong> Employ AI to generate extensive
      test cases or provide debugging hints, allowing the human developer to methodically
      verify solutions and pinpoint issues more rapidly.
    </li>
    <li>
      <strong>Focus on the "whole job":</strong> By offloading rudimentary research
      or initial boilerplate generation, AI can free up mental bandwidth. This enables
      developers to put a renewed focus back on understanding the entire system,
      from database design to deployment, and to take every aspect of the job seriously—because
      no part of the stack is truly "boilerplate" if it's contributing to systemic
      issues.
    </li>
  </ul>

  <p>
    Therefore, for those whose roles have always demanded strategic oversight,
    architectural prowess, and the ability to navigate ambiguous, large-scale
    challenges—like diagnosing and fixing systemic bugs, architecting complex
    integrations, or optimizing for extreme performance scenarios—AI is not a
    replacement, nor is it a universal time-saver for direct code generation.
    Instead, its value lies in acting as an advanced assistant for specific,
    well-defined queries, or as a powerful learning tool, rather than a primary
    code producer for experienced hands.
  </p>

  <p>
    For developers with strengths in areas like complex frontends, performance,
    and reactivity, this evolution still presents an opportunity for strategic
    leverage, provided they lean into the higher-level skills:
  </p>

  <ul>
    <li>
      <strong
        >Complex Frontends, Performance, and Reactivity as Core Strengths:</strong
      > These aren't just about coding; they're about designing intuitive, robust,
      and delightful user experiences. Optimizing rendering paths, managing large
      data sets, minimizing network requests, and implementing effective caching
      strategies requires deep understanding of browser mechanics, network protocols,
      and application architecture. Your ability to reason about user flows, optimize
      for perceived performance, and architect intricate client-side logic will be
      even more valuable.
    </li>
    <li>
      <strong>Focus on Architectural & Design Leadership:</strong> As AI assists
      with more routine code, your time will be freed up to focus on higher-level
      concerns: how the system works, why it's built that way, and what user problems
      it solves. This includes designing overall frontend structures, choosing appropriate
      state management, and ensuring scalability.
    </li>
    <li>
      <strong>Strategically Embracing the AI-Augmented Engineer Role:</strong>
      This means effectively using AI in your daily workflow, understanding its limitations,
      and knowing when to opt for manual work. It's about:
      <ul>
        <li>
          <strong>Contextual Prompt Engineering:</strong> Learning to effectively
          prompt LLMs for specific snippets, exploring unfamiliar concepts, or for
          truly novel boilerplate that falls outside existing patterns, rather than
          for general component generation.
        </li>
        <li>
          <strong>AI-Assisted Refactoring & Testing (with Oversight):</strong>
          Using AI tools to suggest refactoring options or generate test cases, but
          always with careful human review to ensure correctness and adherence to
          complex project contexts.
        </li>
        <li>
          <strong>Performance Diagnostics:</strong> Exploring how AI can analyze
          performance metrics and suggest areas for improvement, then using your
          human expertise to implement the most effective solutions.
        </li>
        <li>
          <strong>Code Review:</strong> Utilizing AI to catch common errors or suggest
          improvements, freeing you up to focus on architectural soundness and business
          logic during code reviews.
        </li>
      </ul>
    </li>
  </ul>

  <p>
    The true evolution of the software engineering role, then, isn't about AI
    replacing humans, but about it <strong>elevating the human role</strong>.
    The demand for skills like:
  </p>

  <ul>
    <li>High-level system design and architectural thinking.</li>
    <li>Translating vague business problems into clear technical solutions.</li>
    <li>Understanding and mitigating ethical considerations.</li>
    <li>
      Mastering the art of effectively leveraging and orchestrating AI tools
      (and knowing when not to).
    </li>
    <li>
      Complex problem-solving and nuanced debugging that spans multiple domains.
    </li>
    <li>
      Human-centric skills: communication, collaboration, mentorship, and user
      empathy.
    </li>
  </ul>

  <p>
    These are the critical areas where human expertise remains essential.
    Engineers who have been operating at this level, often by necessity in their
    career paths, are uniquely positioned to thrive in the AI-augmented future.
    Those whose experience has kept them largely within the realm of
    well-defined, routine coding might indeed find their roles shifting,
    requiring them to quickly pivot towards these higher-order skills.
  </p>

  <p>
    So, the next time you see a post praising (or dismissing) AI's impact,
    remember the magic eye. The perspective on display might simply reflect a
    vastly different experience with what constitutes "normal" or "routine"
    development work. For some, AI is a godsend automating the tedious. For
    others, it's a powerful new tool that simply allows them to focus even more
    intensely on the complex, creative challenges they've always tackled.
  </p>
</BlogLayout>
